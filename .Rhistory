# load libraries
library(kableExtra)                     # for printing tables
library(cowplot)                        # for side by side plots
library(lubridate)                      # for dealing with dates
library(maps)                           # for creating maps
library(flextable)                      # creating contingency tables
library(corrplot)                       # creating correlation matrices
library(tidyverse)
library(tidyquant)
master_data = read_csv('data/clean/train_data.csv')
setwd('C:/Users/Mahima Sangli/OneDrive/Documents/2021-2022 School Year/STAT 471/election-final-project')
master_data = read_csv('data/clean/train_data.csv')
correlations = cor(nums) %>%
apply(1, round, digits=2)
correlations[upper.tri(correlations)] <- NA # erase the upper triangle
diag(correlations) <- NA
flex_correlations = correlations %>%
as.data.frame() %>%
rownames_to_column("var") %>%
flextable::flextable() %>%
flextable::bg(j = 2:ncol(correlations),
bg = function(x){
out <- rep("transparent", length(x))
out[x < -0.7 | x > 0.7] <- "light blue"
out
})
x_cts = x_cts[-1:-12]
nums = master_data %>% select(x_cts)
dtypes = sapply(colnames(master_data), function(x) class(master_data[[x]]))
x_cats = dtypes[dtypes=='character'] %>%
names()
x_cts = dtypes[dtypes=='numeric'] %>%
names()
y = master_data$leading_party
x_cts = x_cts[-1:-12]
nums = master_data %>% select(x_cts)
correlations = cor(nums) %>%
apply(1, round, digits=2)
correlations[upper.tri(correlations)] <- NA # erase the upper triangle
diag(correlations) <- NA
flex_correlations = correlations %>%
as.data.frame() %>%
rownames_to_column("var") %>%
flextable::flextable() %>%
flextable::bg(j = 2:ncol(correlations),
bg = function(x){
out <- rep("transparent", length(x))
out[x < -0.7 | x > 0.7] <- "light blue"
out
})
flex_correlations
save_as_docx(
"Corrleation Matrix" = flex_correlations, path = "results/corrMatrix.docx")
corrMtrix[upper.tri(correlations)]
corrMatrix[upper.tri(correlations)]
nums = master_data %>% select(x_cts)
corrMatrix = corrplot(cor(nums))
corrMatrix[upper.tri(correlations)]
corrMatrix
cor[upper.tri(cor)] <- NA
COR
cor
class(cor)
nums = master_data %>% select(x_cts)
cor1 = cor(nums)
cor1 = cor1 %>%
apply(1,round,digits=2)
cor1[upper.tri(cor1)] <- NA
cor1
diag(cor1) <- NA
corrMatrix = corrplot(cor1)
save_as_pptx('Correlation Matrix' = corrMatrix, path = 'results/corrMatrix.pptx')
nums = master_data %>% select(x_cts)
cor1 = cor(nums)
cor1 = cor1 %>%
apply(1,round,digits=2)
table(cor1)
library(Hmisc)                          # creating correlation matrices
cor1<-rcorr(as.matrix(master_data[,1:12]))
cor1<-rcorr(as.matrix(master_data[x_cts]))
cor1
master_data[x_cts]
master_data[,1:7]
as.matrix(master_data[x_cts])
cor(as.matrix(master_data[x_cts]))
rcorr(as.matrix(master_data[x_cts]))
scatterplot(x=master_data$severe_housing_issues,y=master_data$poor_mental_health_days)
ggplot(aes(x=master_data$severe_housing_issues,y=master_data$poor_mental_health_days)) + geom_point()
master_data %>% ggplot(aes(x=severe_housing_issues,y=poor_mental_health_days)) + geom_point()
cor(master_data$severe_housing_issues,master_data$poor_mental_health_days)
rcorr(master_data$severe_housing_issues,master_data$poor_mental_health_days)
cor1<-rcorr(as.matrix(master_data[x_cts]))
corrMatrix = flattenCorrMatrix(cor1$r)
library(corrplot)
cor1<-rcorr(as.matrix(master_data[x_cts]))
corrMatrix = flattenCorrMatrix(cor1$r)
flattenCorrMatrix <- function(cormat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
corrMatrix = flattenCorrMatrix(cor1$r)
flattenCorrMatrix <- function(cormat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut]
)
}
corrMatrix = flattenCorrMatrix(cor1$r)
corrMatrix
class(corrMatrix)
corrMatrix2 = corrMatrix %>%
filter(cor > 0.7 | cor < 0.7)
corrMatrix2
corrMatrix2 = corrMatrix %>%
filter(cor > 0.7 | cor < -0.7)
corrMatrix2
colnames(master_data)
master_data = read_csv('data/clean/train_data.csv')
##dataset contains mixed data types - create lists of categorical vs. numerical columns
#named vector containing dtypes
dtypes = sapply(colnames(master_data), function(x) class(master_data[[x]]))
x_cats = dtypes[dtypes=='character'] %>%
names()
x_cts = dtypes[dtypes=='numeric'] %>%
names()
y = master_data$leading_party
x_cts
x_cts = x_cts[-1:-12]
#correlation matrix between explanatory variables
cor1<-rcorr(as.matrix(master_data[x_cts]))
#define flattening function
flattenCorrMatrix <- function(cormat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut]
)
}
#flatten
corrMatrix = flattenCorrMatrix(cor1$r)
#focus on strongest correlations
corrMatrix2 = corrMatrix %>%
filter(cor > 0.7 | cor < -0.7)
corrMatrix2
corrMatrix2 = corrMatrix %>%
filter(cor > 0.7 | cor < -0.7) %>%
order(cor)
flattenCorrMatrix <- function(cormat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
corr  =(cormat)[ut]
)
}
#flatten
corrMatrix = flattenCorrMatrix(cor1$r)
#focus on strongest correlations
corrMatrix2 = corrMatrix %>%
filter(corr > 0.7 | corr < -0.7) %>%
order(corr)
corrMatrix2 = corrMatrix %>%
filter(corr > 0.7 | corr < -0.7) %>%
ordered_corrDF = corrMatrix2[order(corrMatrix2$corr), ]
corrMatrix = flattenCorrMatrix(cor1$r)
#focus on strongest correlations
corrMatrix2 = corrMatrix %>%
filter(corr > 0.7 | corr < -0.7)
ordered_corrDF = corrMatrix2[order(corrMatrix2$corr), ]
ordered_corrDF
library(Hmisc)
cor1<-rcorr(as.matrix(master_data[x_cts]))
#define flattening function
flattenCorrMatrix <- function(cormat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
corr  =(cormat)[ut]
)
}
#flatten
corrMatrix = flattenCorrMatrix(cor1$r)
#focus on strongest correlations
corrMatrix2 = corrMatrix %>%
filter(corr > 0.7 | corr < -0.7)
ordered_corrDF = corrMatrix2[order(corrMatrix2$corr), ]
ordered_coffDF
ordered_corrDF
ordered_corrDF = corrMatrix2[order(corrMatrix2$corr), ] %>%
write_tsv(
"results/ordered_corrDF.tsv"
)
ordered_corrDF[c(-1:-10),]
ordered_corrDF[c(1:10,-1:-10)]
ordered_corrDF[c(1:10,-1:-10),]
ordered_corrDF %>% head(5)
read_tsv("../results/ordered_corrDF.tsv")[-1,]
read_tsv("results/ordered_corrDF.tsv")
read_tsv("results/ordered_corrDF.tsv")[-1,]
health_box = master_data %>%
ggplot(aes(x=poor_fair_health, y=leading_party, fill=leading_party)) +
geom_boxplot() +
labs(x = "Health Score",
y = "Leading Party") +
scale_fill_manual(breaks = c("Democrat", "Republican"),
values = c("blue", "red"))
ggsave(
filename = "results/health-box.png",
plot = health_box,
device = "png",
width = 9,
height = 9
)
getwd()
glm_features = read_tsv('results/glm-features-table.tsv')
glm_features
train_data
train_data = read_csv("data/clean/train_data.csv")
length(colnames(train_data))
colnames(train_data)
glm_features$feature
train_data = read_csv("data/clean/train_data.csv")
train_data = train_data %>%
mutate(leading_party = as.numeric(leading_party == "Democrat")) %>%
select(-state, -county, -fips, -total_votes, -Democrat, -Other, -Republican, -Green, -Libertarian, -pct_dem, -pct_rep, -pct_other, -pct_green, -pct_libertarian)
train_data$urban_rural_desc = as.factor(train_data$urban_rural_desc)
# run logistic regression
glm_fit = glm(leading_party ~ .,
family = "binomial",
data = train_data)
summary(glm_fit)
summary = summary(glm_fit)
summary$coefficients
class(summary$coefficients)
as.tibble(summary$coefficients)
summary = summary(glm_fit)
glm_results = as_tibble(summary$coefficients,rownames = NA)
glm_results
summary = summary(glm_fit)
summary$coefficients %>%
write.table('results/glm-coef-p.txt')
rownames(summary$coefficients)
summary$coefficients
summary
summary
beta_hat_std
# run lasso regression
set.seed(471)
lasso_fit = cv.glmnet(leading_party ~ .,
alpha = 1,
family = "binomial",
type.measure = "class",
data = train_data)
# save the lasso fit object
save(lasso_fit, file = "results/lasso_fit.Rda")
# create lasso CV plot
png(width = 6,
height = 4,
res = 300,
units = "in",
filename = "results/lasso-cv-plot.png")
plot(lasso_fit)
dev.off()
# create lasso trace plot
p = plot_glmnet(lasso_fit, train_data, features_to_plot = 6)
ggsave(filename = "results/lasso-trace-plot.png",
plot = p,
device = "png",
width = 6,
height = 4)
# extract features selected by lasso and their coefficients
beta_hat_std = extract_std_coefs(lasso_fit, train_data)
getwd()
###Load appropriate packages
library(rpart)         # to train decision trees
library(rpart.plot)    # to plot decision trees
library(randomForest)  # random forests
library(gbm)           # boosting
library(tidyverse)     # tidyverse
library(kableExtra)    # for printing tables
library(cowplot)       # for side-by-side plots
###Data Preparation
##Read in data
train = read_csv("data/clean/train_data.csv")
train = train %>%
mutate(leading_party = as.numeric(leading_party == "Democrat")) %>%
select(-state, -county, -fips, -total_votes, -Democrat, -Other, -Republican, -Green, -Libertarian, -pct_dem, -pct_rep, -pct_other, -pct_green, -pct_libertarian)
train$urban_rural_desc = as.factor(train$urban_rural_desc)
###Decision Tree
##Growing the default tree
#fit
tree_fit = rpart(leading_party ~ .,
method = 'class',
parms = list(split = 'gini'),
data = train)
#plot
rpart.plot(tree_fit)
##Deepest possible tree
#fit
T_0 = rpart(leading_party ~ .,
method = 'class',
parms = list(split = 'gini'),
control = rpart.control(minsplit = 1,
minbucket = 1,
cp = 0),
data = train)
#cp table
cp_table = printcp(T_0) %>%
as_tibble()
##Pruning and cross-validation
#cv plot
cv_plot = cp_table %>%
filter(nsplit >= 2) %>%
ggplot(aes(x = nsplit+1, y = xerror,
ymin = xerror - xstd, ymax = xerror + xstd)) +
geom_point() + geom_line() +
geom_errorbar(width = 0.2) +
xlab("log10(Number of terminal nodes)") + ylab("CV error") +
geom_hline(aes(yintercept = min(xerror)), linetype = "dashed") +
scale_x_log10()
theme_bw()
#optimal tree
set.seed(471)
optimal_tree_info = cp_table %>%
filter(xerror - xstd < min(xerror)) %>%
arrange(nsplit) %>%
head(1)
optimal_tree_info
optimal_tree = prune(tree = T_0, cp = optimal_tree_info$CP)
plot(optimal_tree)
rpart.plot(optimal_tree)
optimal_tree_info
optimal_tree_plot = rpart.plot(optimal_tree)
optimal_tree_plot
set.seed(471) # for reproducibility (DO NOT CHANGE)
rf_fit = randomForest(factor(leading_party) ~ ., data = train)
#OOB error
def_OOB_plot = tibble(oob_error = rf_fit$err.rate[,"OOB"],trees = 1:500) %>%
ggplot(aes(x = trees, y = oob_error)) + geom_line() + theme_bw()
def_OOB_plot
set.seed(471) # for reproducibility (DO NOT CHANGE)
#test out 5 different ms
poss_m = seq(1,57,length.out=5)
vec.OOB_err = c() #empty container to store OOB error values
for(i in poss_m){
rf_fit2 = randomForest(factor(leading_party) ~ .,
mtry = i,
ntrees = 300,
data = train)
OOB_err = rf_fit2$err.rate[,"OOB"][300]
vec.OOB_err = c(vec.OOB_err,OOB_err)
}
#create tibble
m_OOB_err = tibble(m = poss_m,
OOB_err = round(vec.OOB_err,4))
#plot the data
m_OOB_err_plot = m_OOB_err %>%
ggplot(aes(x = m, y = OOB_err)) +
geom_point() + geom_text(aes(label=m,hjust=2, vjust=1)) +
xlab("Value of m") + ylab("OOB Error") +
theme_bw()
ggsave(filename = "results/def_OOB_plot.png",
plot = p,
device = "png",
width = 6,
height = 4)
ggsave(filename = "results/def_OOB_plot.png",
plot = def_OOB_plot,
device = "png",
width = 6,
height = 4)
ggsave(filename = "results/m_OOB_err_plot.png",
plot = m_OOB_err_plot,
device = "png",
width = 6,
height = 4)
var_imp = varImpPlot(rf_fit3,n.var=10)
save(rf_fit3, file = "results/rf_fit.Rda")
set.seed(471) # for reproducibility (DO NOT CHANGE)
rf_fit3 = randomForest(factor(leading_party) ~ .,
mtry = 29,
importance = TRUE,
data = train)
var_imp = varImpPlot(rf_fit3,n.var=10)
ggsave(filename = "results/rf_varimp.png",
plot = var_imp,
device = "png",
width = 6,
height = 4)
set.seed(471) # for reproducibility (DO NOT CHANGE)
#interaction depth 1
gbm_fit1 = gbm(leading_party ~ .,
distribution = "bernoulli",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
#interaction depth 2
gbm_fit2 = gbm(leading_party ~ .,
distribution = "bernoulli",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
#interaction depth 3
gbm_fit3 = gbm(leading_party ~ .,
distribution = "bernoulli",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = train)
##Optimal fit
#CV Errors
ntrees = 1000
CV_errors = tibble(Iteration = 1:ntrees, CV_1 = gbm_fit1$cv.error,
CV_2 = gbm_fit2$cv.error, CV_3 = gbm_fit3$cv.error)
gbm_CV_errs = CV_errors %>%
ggplot() +
geom_line(aes(x = Iteration, y = CV_1, color = 'depth 1')) +
geom_hline(yintercept=min(CV_errors$CV_1),linetype = 'dashed') +
geom_line(aes(x = Iteration, y = CV_2, color = 'depth 2')) +
geom_hline(yintercept=min(CV_errors$CV_2),linetype = 'dashed') +
geom_line(aes(x = Iteration, y = CV_3, color = 'depth 3')) +
geom_hline(yintercept=min(CV_errors$CV_3),linetype = 'dashed') +
xlab("Number of Trees") + ylab("CV error") +
theme_bw()
gbm_CV_errs
gbm_fit_optimal = gbm_fit3
optimal_num_trees = gbm.perf(gbm_fit3, plot.it = FALSE)
optimal_num_trees
ggsave('results/gbm_CV_errs.png',
plot = var_imp,
device = "png",
width = 6,
height = 4)
class(gbm_CV_errs)
ggsave('results/gbm_CV_errs.png',
plot = gbm_CV_errs,
device = "png",
width = 6,
height = 4)
rel_inf = summary(gbm_fit_optimal, n.trees = optimal_num_trees, plotit = FALSE)[1:10,] %>%
as_tibble()
rel_inf
rel_inf = summary(gbm_fit_optimal, n.trees = optimal_num_trees, plotit = FALSE)[1:10,] %>%
as_tibble() %>% write_tsv("results/gbm-rel-inf.tsv")
p1 = plot(gbm_fit_optimal, i.var = "log_traffic_volume", n.trees = optimal_num_trees)
#p2
p2 = plot(gbm_fit_optimal, i.var = "log_poverty_rating", n.trees = optimal_num_trees)
#p3
p3 = plot(gbm_fit_optimal, i.var = "severe_housing_issues", n.trees = optimal_num_trees)
part_dep_plots = plot_grid(p1,p2,p3)
ggsave('results/part-dep-plots.png',
plot = part_dep_plots,
device = "png",
width = 6,
height = 4)
part_dep_plots
ggsave(filename = "results/rf_varimp.png",
plot = var_imp,
device = "png",
width = 6,
height = 4)
optimal_tree_plot = rpart.plot(optimal_tree)
rpart.plot(optimal_tree)
